{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee997dcb",
   "metadata": {},
   "source": [
    "# ğŸ“Š Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ ØªØ§ÛŒÛŒØ¯ ÙˆØ§Ù… Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÛŒØ§Ø¯Ú¯ÛŒØ±ÛŒ Ù…Ø§Ø´ÛŒÙ†\n",
    "Ø§ÛŒÙ† Ù†ÙˆØªâ€ŒØ¨ÙˆÚ© Ù¾Ø±ÙˆÚ˜Ù‡â€ŒØ§ÛŒ Ú©Ø§Ù…Ù„ Ø¨Ø±Ø§ÛŒ Ø¨Ø±Ø±Ø³ÛŒ ÙˆØ§Ø¬Ø¯ Ø´Ø±Ø§ÛŒØ· Ø¨ÙˆØ¯Ù† Ø§ÙØ±Ø§Ø¯ Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª ÙˆØ§Ù… Ø§Ø³ØªØŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ loan Ø´Ø§Ù…Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ØŒ Ù…Ø¯Ù„â€ŒØ³Ø§Ø²ÛŒØŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ùˆ Ø¨Ù‡Ø¨ÙˆØ¯."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d50e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡\n",
    "df = pd.read_csv('loan.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb102dd",
   "metadata": {},
   "source": [
    "## ğŸ” Ø¨Ø±Ø±Ø³ÛŒ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ù‚Ø§Ø¯ÛŒØ± Ú¯Ù…Ø´Ø¯Ù‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d486b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ø¨Ø±Ø±Ø³ÛŒ Ù…Ù‚Ø§Ø¯ÛŒØ± Ú¯Ù…Ø´Ø¯Ù‡\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6572d51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ù‚Ø§Ø¯ÛŒØ± Ú¯Ù…Ø´Ø¯Ù‡\n",
    "cat_cols = df.select_dtypes(include='object').columns\n",
    "num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "imputer_cat = SimpleImputer(strategy='most_frequent')\n",
    "imputer_num = SimpleImputer(strategy='mean')\n",
    "\n",
    "df[cat_cols] = imputer_cat.fit_transform(df[cat_cols])\n",
    "df[num_cols] = imputer_num.fit_transform(df[num_cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20479941",
   "metadata": {},
   "source": [
    "## ğŸ”¢ Ú©Ø¯Ú¯Ø°Ø§Ø±ÛŒ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ ØºÛŒØ± Ø¹Ø¯Ø¯ÛŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e6bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "le = LabelEncoder()\n",
    "for col in cat_cols:\n",
    "    df[col] = le.fit_transform(df[col])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20172a02",
   "metadata": {},
   "source": [
    "## âœ‚ï¸ ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ù‡ Ø¢Ù…ÙˆØ²Ø´ØŒ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ùˆ ØªØ³Øª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c85fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df.drop('Loan_Status', axis=1)\n",
    "y = df['Loan_Status']\n",
    "\n",
    "# ØªÙ‚Ø³ÛŒÙ… Ø¨Ù‡ ØªØ³Øª Ùˆ Ø¨Ù‚ÛŒÙ‡\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.15, random_state=42, stratify=y)\n",
    "# ØªÙ‚Ø³ÛŒÙ… Ø¢Ù…ÙˆØ²Ø´ Ùˆ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2353, random_state=42, stratify=y_train_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a518565",
   "metadata": {},
   "source": [
    "## âš–ï¸ Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a60544",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = X_train.copy()\n",
    "X_val_scaled = X_val.copy()\n",
    "X_test_scaled = X_test.copy()\n",
    "\n",
    "X_train_scaled[num_cols] = scaler.fit_transform(X_train[num_cols])\n",
    "X_val_scaled[num_cols] = scaler.transform(X_val[num_cols])\n",
    "X_test_scaled[num_cols] = scaler.transform(X_test[num_cols])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579349e1",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ Ø¨Ø®Ø´ Ø¨Ù‡Ø¨ÙˆØ¯: Ù…Ù‡Ù†Ø¯Ø³ÛŒ ÙˆÛŒÚ˜Ú¯ÛŒ (Total_Income)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00456330",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Total_Income'] = df['ApplicantIncome'] + df['CoapplicantIncome']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15021e08",
   "metadata": {},
   "source": [
    "## âš™ï¸ Ø¨Ø®Ø´ Ø¨Ù‡Ø¨ÙˆØ¯: Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² SMOTE Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ù„Ø§Ù†Ø³ Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdc6297",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = sm.fit_resample(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f246c61",
   "metadata": {},
   "source": [
    "## ğŸ¤– Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„â€ŒÙ‡Ø§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb210458",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"ANN\": MLPClassifier(hidden_layer_sizes=(10,10), max_iter=1000)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nModel: {name}\")\n",
    "    model.fit(X_resampled, y_resampled)\n",
    "    preds = model.predict(X_val_scaled)\n",
    "    print(classification_report(y_val, preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0bc9e2",
   "metadata": {},
   "source": [
    "## ğŸ“Š Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø±ÙˆÛŒ Ø¯Ø§Ø¯Ù‡ ØªØ³Øª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fea2ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nModel: {name}\")\n",
    "    test_preds = model.predict(X_test_scaled)\n",
    "    print(classification_report(y_test, test_preds))\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
